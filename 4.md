4.log_cutting：
日志切割，有这样一个access.log每天会打出大量的日志。实现一个日志切割的功能，并说明该实现方式会有什么缺陷。

	答：我们可以通过split操作对access.log文件进行分割，我们以文件的大小作为分割的依据，下面的语句实现了以将日志分割为2M的日志文件：
	split -b 2m access.log new_access.log
  这种单纯的分割配合定时任务cron服务使用可以起到不错的效果。cron本身提供了hourly，daily，weekly，
  将上述的脚本放在/etc/cron.hourly 目录下会使分割操作没隔一个小时执行一次，不过得改下文件的命名方式，我么可以以时间为文件名：
  split -b 2m access.log access_$(date +%Y-%m-%d-%H-%M).log。
  也可以自己定时：
  20* * * * split -b 2m access.log access_$(date +%Y-%m-%d-%H-%M).log 即20分钟执行一个分割操作。
  优点：结合以文件大小为条件的切割和定时操作，实现了将某段时间的日志取出并分割成很多个较小的日志文件，当我们需要对日志进行查找是，
  可以更容易的查找。
  缺点：随着时间的增加，会生成很多的这种日志文件，在造成硬盘脆片的同时，可能会趋于每个目录下节点数量的限制，
  所以还得周期性的对文件进行删除或者整理
